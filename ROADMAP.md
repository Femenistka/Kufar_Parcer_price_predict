## Архитектура проекта (MVP)

Ниже описана модульная архитектура MVP-сервиса, который:

1. по кнопке в веб-интерфейсе парсит актуальные объявления с Kufar по синтезаторам/пианино,
2. сохраняет данные в БД,
3. извлекает признаки (характеристики),
4. прогоняет сохранённую (уже обученную) ML-модель регрессии для оценки “рыночной цены”,
5. сравнивает оценку с ценой в объявлении и выводит список “выгодных” вариантов.

---

## Общая схема потоков данных

### Поток `Scan -> Store -> Predict -> Show`

1. **UI (Streamlit)**: пользователь выбирает запросы/фильтры и нажимает кнопку `Scan`.
2. **Scraper** загружает результаты поиска Kufar (1–N страниц), парсит карточки объявлений.
3. **DB layer** сохраняет новые объявления и обновляет существующие (дедупликация по `source_id`/`url`).
4. **Feature extraction** извлекает характеристики из `title/description` (бренд, модель, 88 клавиш и т.д.) и пишет в таблицу `features`.
5. **ML inference** собирает фичи в единый вектор, загружает модель (joblib/pickle), считает `predicted_market_price` и метрики отклонения (`delta`, `delta_pct`), сохраняет в `predictions`.
6. **UI** показывает таблицу объявлений + сортировки/фильтры (например “недооценено на 20%+”).

---

## Компоненты и ответственность

### 1) Web UI (Streamlit)

**Назначение:** интерфейс запуска сканирования и просмотра результатов.

**Задачи:**

* форма выбора поисковых запросов/категорий и лимитов (страницы/кол-во объявлений);
* кнопка запуска: `Scan Kufar`;
* страница результатов: таблица объявлений, фильтры (бренд, цена, свежесть, “выгодность”), сортировки;
* отображение логов/статистики: сколько найдено, сколько новых/обновлённых, ошибки.

---

### 2) Scraper (Kufar)

**Назначение:** загрузка и парсинг объявлений.

**Задачи:**

* построение URL поиска Kufar по запросам (synth/piano + ключевые слова);
* скачивание HTML/JSON (в зависимости от доступного формата);
* парсинг минимальных полей объявления:

  * `source_id` (если доступен), `url`, `title`, `price`, `currency`, `published_at`, `location`, `description/raw_text`;
* нормализация цены (в число) и дат;
* ограничение нагрузки: лимит страниц, задержки, обработка ошибок/таймаутов.

**Выход:** список структурированных `ListingRaw` объектов.

---

### 3) Feature Extraction (извлечение характеристик)

**Назначение:** превратить текст объявления в признаки для модели.

**Задачи MVP:**

* `brand` — словарь брендов (Yamaha, Casio, Roland, Korg, Nord…);
* `model` — regex-паттерны (например `CDP-\d+`, `P-\d+`, `FP-\d+`, `PSR-\w+`);
* `keys` — 61/76/88 (по regex “88 клавиш”, “88 keys”);
* `hammer_action` — по словам “молоточк”, “hammer action”, “weighted”;
* `velocity` — “touch”, “velocity”, “чувствительность”.

**Принципы:**

* если значение не найдено → `unknown` / `NULL`, без догадок;
* хранить “сырые” признаки и при необходимости расширять парсер без изменения схемы объявлений.

---

### 4) ML Inference (прогноз рыночной цены)

**Назначение:** использовать готовую модель регрессии для оценки цены.

**Задачи:**

* загрузка модели из `artifacts/` (например `model.joblib`, `preprocessor.joblib` или единый pipeline);
* сбор `feature_row` из таблиц `listings + features`;
* обработка пропусков согласно тому, как модель обучалась (`unknown` для категорий, `NaN` для чисел);
* прогноз `predicted_price`;
* расчёт метрик сравнения:

  * `delta = predicted_price - listing_price`
  * `delta_pct = delta / listing_price * 100`
* запись результата в `predictions` с `model_version`.

---

### 5) Database Layer (SQLite для MVP)

**Назначение:** единое место хранения объявлений, признаков и предсказаний.

**Задачи:**

* дедупликация и обновление объявлений (по `source_id` или `url`);
* хранение истории предсказаний (или перезапись — как выберешь; в MVP можно хранить последнее);
* выдача данных в UI с фильтрами/сортировками.

